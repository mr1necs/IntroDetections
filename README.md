# Intro Detection

Самый простой способ поиска коротких заставок в сериалах — это обнаружение повторяющихся фрагментов в эпизодах одного сериала. Обычно заставки в пределах одного сериала (или сезона) практически не меняются. Однако данный подход не всегда эффективен, так как помимо заставок часто повторяются также заставки от телестудий, переводчиков, рекламные вставки и титры. Поэтому требуется более точный и надежный метод. Поэтому приходится применять более слоджные методы.

### Lightweight метод

#### Алгоритм работы

1. **Извлечение кадров**
   Видео разбивается на кадры с фиксированным интервалом.

2. **Экстракция признаков**
   Из каждого кадра извлекаются признаки с помощью предобученной нейронной сети (ResNet50 без верхних слоёв).

3. **Формирование шаблона заставки (template)**
   На обучающей выборке анализируются окна фиксированной длины (5–10 секунд), усредняются признаки кадров внутри окон по сериям, выбирается окно с минимальной дисперсией (часто повторяющееся).

4. **Поиск в новых сериях**
   В тестовых видео производится скользящий поиск, вычисляются признаки и сравниваются с шаблоном с помощью косинусного сходства. Максимально похожее окно определяется как заставка.

#### Преимущества и недостатки

* Простота и минимальные настройки.
* Хорошо обобщается на сериалы с похожими заставками.
* Чувствителен к монтажу и цветокоррекции.

#### Возможные улучшения

* Многоступенчатый поиск (PCA → DTW).
* Темпоральные модели (CNN/LSTM).
* Интеграция OCR для текстовой проверки.

### BinaryСlassification метод 

#### Алгоритм работы

1. **Подготовка данных**
   Видео нарезается на короткие клипы (например, 16 кадров по 1 кадру в секунду).

2. **Разметка клипов**
   Клипы размечаются бинарно: "1" если центральный кадр попадает в заставку, иначе "0".

3. **Обучение модели**
   На размеченных данных обучается бинарная модель классификации, например, 3D CNN.

4. **Инференс через скользящее окно**
   В длинных видео модель применяется в режиме скользящего окна с небольшим шагом, выдавая вероятность наличия заставки.

5. **Агрегация результатов**
   Высокие вероятности объединяются, выделяя наиболее подходящий интервал для заставки.

#### Преимущества и недостатки

* Высокая точность классификации.
* Хорошо адаптируется под различные виды заставок.
* Требует значительных вычислительных ресурсов.
* Необходимость большого объёма размеченных данных для обучения.
* Более сложная реализация по сравнению с Lightweight подходом.

#### Возможные улучшения

* Использование темпоральных моделей для повышения точности.
* Применение двухступенчатого подхода: грубая классификация → уточнение границ.
* Интеграция OCR для дополнительной верификации.

В целом эта 2 основных пеодхода которые я реализовал оба решения есть в файлах репозитория
