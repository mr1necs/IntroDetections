{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Подготовка окружения (импорт библиотек)",
   "id": "a411c67f42ef1afc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:40:30.316782Z",
     "start_time": "2025-06-17T19:40:29.036863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.io as io\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from tqdm.auto import tqdm"
   ],
   "id": "bb39c3409c47cf3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Конфигурация",
   "id": "ab62251f59b39710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:40:30.858141Z",
     "start_time": "2025-06-17T19:40:30.855187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration\n",
    "BASE_DIR = Path().resolve()                         # Root directory of the project\n",
    "TRAIN_VIDEO_DIR = BASE_DIR / \"data_train_short/\"    # directory with train .mp4 files named as <video_id>.mp4\n",
    "TEST_VIDEO_DIR = BASE_DIR / \"data_test_short/\"      # directory with test  .mp4 files named as <video_id>.mp4\n",
    "TRAIN_JSON = BASE_DIR / \"train_labels.json\"         # json mapping train video_id -> {\"start\", \"end\"}\n",
    "TEST_JSON = BASE_DIR / \"test_labels.json\"           # json mapping test  video_id -> {\"start\", \"end\"}\n",
    "FRAME_RATE = 2                                      # fps for sampling\n",
    "WINDOW_SEC = 15                                     # window length in seconds\n",
    "STRIDE_SEC = 1                                      # stride in seconds"
   ],
   "id": "a48944094854b539",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-17T19:40:31.336335Z",
     "start_time": "2025-06-17T19:40:31.315912Z"
    }
   },
   "source": [
    "# Device selection: MPS > CUDA > CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Model use device:\", DEVICE)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model use device: mps\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Инициализация модели и трансформаций",
   "id": "ba7639f811c3b6f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:40:32.439737Z",
     "start_time": "2025-06-17T19:40:32.437037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocessing transform for video clips\n",
    "video_transform = T.Compose([\n",
    "    T.Resize((112, 112)),  # resize frames\n",
    "    T.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989]),\n",
    "])\n"
   ],
   "id": "18850cf19bad58b5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:40:33.693994Z",
     "start_time": "2025-06-17T19:40:33.057748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load pretrained 3D ResNet and adjust head\n",
    "torch.set_grad_enabled(False)\n",
    "model = r3d_18(weights=R3D_18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # binary output\n",
    "model.to(DEVICE)\n",
    "model.train()"
   ],
   "id": "c78734f7e5614d2c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoResNet(\n",
       "  (stem): BasicStem(\n",
       "    (0): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Загрузка и слияние меток",
   "id": "6c6475f3b0599453"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:40:35.642763Z",
     "start_time": "2025-06-17T19:40:35.637508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and merge label files\n",
    "def load_labels_from_dir(json_path: Path) -> dict:\n",
    "    with json_path.open('r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_labels = load_labels_from_dir(TRAIN_JSON)\n",
    "test_labels  = load_labels_from_dir(TEST_JSON)\n",
    "\n",
    "# Merge two dicts\n",
    "labels = {**train_labels, **test_labels}"
   ],
   "id": "599e57178bdc75a5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:40:36.271810Z",
     "start_time": "2025-06-17T19:40:36.268497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert time string to seconds\n",
    "def time_to_seconds(t_str):\n",
    "    parts = list(map(int, t_str.split(':')))\n",
    "    if len(parts) == 3:\n",
    "        h, m, s = parts\n",
    "        return h * 3600 + m * 60 + s\n",
    "    elif len(parts) == 2:\n",
    "        m, s = parts\n",
    "        return m * 60 + s\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid time format: {t_str}\")\n"
   ],
   "id": "773a89ed6651d5af",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Определение датасета",
   "id": "a2078768df430924"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:40:38.935705Z",
     "start_time": "2025-06-17T19:40:38.932211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom Dataset for intro detection\n",
    "class VideoIntroDataset(Dataset):\n",
    "    def __init__(self, labels: dict, video_dir: Path, transform=None):\n",
    "        self.labels = labels\n",
    "        self.video_dir = video_dir\n",
    "        self.video_ids = list(labels.keys())\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vid = self.video_ids[idx]\n",
    "        path = self.video_dir / vid / f\"{vid}.mp4\"\n",
    "        video, _, _ = io.read_video(str(path), pts_unit='sec')\n",
    "        # optional: sample frames or clip\n",
    "        if self.transform:\n",
    "            video = self.transform(video)\n",
    "        label = torch.tensor(self.labels[vid]['label'], dtype=torch.long)\n",
    "        return video, label"
   ],
   "id": "f1c5c12ce93e862a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Обучение модели",
   "id": "2cb9a26066dc4975"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:40:59.246317Z",
     "start_time": "2025-06-17T19:40:59.243235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training setup\n",
    "labels = dict(list(labels.items())[:10])\n",
    "dataset = VideoIntroDataset(labels, TRAIN_VIDEO_DIR, transform=video_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # classification loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)"
   ],
   "id": "2fbeafb38ab9edf4",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-06-17T19:40:59.681155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "    total, correct = 0, 0\n",
    "    for videos, targets in tqdm(dataloader, desc=f\"Epoch {epoch}\"):\n",
    "        videos, targets = videos.to(DEVICE), targets.to(DEVICE)\n",
    "        logits = model(videos)\n",
    "        loss = criterion(logits, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total += targets.size(0)\n",
    "        correct += (preds == targets).sum().item()\n",
    "\n",
    "    print(f\"Epoch {epoch} — Loss: {loss:.4f}, Acc: {correct/total:.3f}\")"
   ],
   "id": "25dbb467333ecbaf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fa5927996db45bdb2fd8bf85926a7ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid NAL unit size (7147 > 2825).\n",
      "missing picture in access unit with size 2841\n",
      "Invalid NAL unit size (7147 > 2825).\n",
      "Error splitting the input into NAL units.\n",
      "Invalid NAL unit size (7147 > 2825).\n",
      "missing picture in access unit with size 2841\n",
      "stream 0, offset 0x12c010e2: partial file\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Детекция и оценка на тестовых данных"
   ],
   "id": "a1e75ca6668b7fe0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sliding-window intro detection\n",
    "def detect_intro(model, video_path: Path, clip_len=WINDOW_SEC, step=STRIDE_SEC, threshold=0.5) -> tuple[float, float]:\n",
    "    \"\"\"Returns (start_sec, end_sec) or (None, None) if no intro detected.\"\"\"\n",
    "    model.eval()\n",
    "    video, _, info = io.read_video(str(video_path), pts_unit=\"sec\")  # Video frames and metadata\n",
    "    fps = info['video_fps']\n",
    "    T_total = video.shape[0]\n",
    "    scores: list[float] = []\n",
    "    times: list[float] = []\n",
    "    # Slide over video\n",
    "    for t0 in range(0, max(1, T_total - clip_len + 1), step):\n",
    "        clip = video[t0:t0 + clip_len]  # select clip\n",
    "        # Prepare tensor: [T, C, H, W]\n",
    "        clip = clip.permute(0, 3, 1, 2) / 255.0\n",
    "        clip = torch.stack([video_transform(frame) for frame in clip])\n",
    "        clip = clip.unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            logits = model(clip)\n",
    "            score = torch.sigmoid(logits).item()  # confidence\n",
    "        scores.append(score)\n",
    "        times.append(t0 / fps)\n",
    "    scores = np.array(scores)\n",
    "    times = np.array(times)\n",
    "    # Mask above threshold\n",
    "    mask = scores > threshold\n",
    "    if not mask.any():\n",
    "        return None, None\n",
    "    # Find longest continuous segment\n",
    "    max_len = 0\n",
    "    best = (0, 0)\n",
    "    start_i = None\n",
    "    for i, m in enumerate(mask):\n",
    "        if m and start_i is None:\n",
    "            start_i = i\n",
    "        if (not m or i == len(mask) - 1) and start_i is not None:\n",
    "            end_i = i if not m else i + 1\n",
    "            length = end_i - start_i\n",
    "            if length > max_len:\n",
    "                max_len = length\n",
    "                best = (start_i, end_i)\n",
    "            start_i = None\n",
    "    s, e = best\n",
    "    # Convert to seconds\n",
    "    start_sec = float(times[s])\n",
    "    end_sec = float(times[e - 1] + clip_len / fps)\n",
    "    return start_sec, end_sec"
   ],
   "id": "7856b7f23ab5db43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# IoU for two intervals\n",
    "def iou_interval(a: int, b: int, c: int, d: int) -> float:\n",
    "    inter = max(0, min(b, d) - max(a, c))\n",
    "    union = (b - a) + (d - c) - inter\n",
    "    return inter / union if union > 0 else 0"
   ],
   "id": "fe06a46da5d38cc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Inference and evaluation\n",
    "model.eval()\n",
    "ious = []\n",
    "for vid, info in tqdm(labels.items(), desc=\"Eval\"):\n",
    "    path = TEST_VIDEO_DIR / vid / f\"{vid}.mp4\"\n",
    "    # define detect_intro to return start/end in seconds\n",
    "    pred_s, pred_e = detect_intro(model, path)\n",
    "    if pred_s is None:\n",
    "        continue\n",
    "    gt_s = time_to_seconds(info['start'])\n",
    "    gt_e = time_to_seconds(info['end'])\n",
    "    ious.append(iou_interval(gt_s, gt_e, pred_s, pred_e))\n",
    "\n",
    "print(f\"Mean IoU: {sum(ious)/len(ious):.3f}\")"
   ],
   "id": "ab3bd971f9d75ba8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "74f7011d547758d4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
